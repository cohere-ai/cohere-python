# This file was auto-generated by Fern from our API Definition.

import typing

import pydantic

from ....core.pydantic_utilities import IS_PYDANTIC_V2
from ....core.unchecked_base_model import UncheckedBaseModel


class Hyperparameters(UncheckedBaseModel):
    """
    The fine-tuning hyperparameters.
    """

    early_stopping_patience: typing.Optional[int] = pydantic.Field(default=None)
    """
    Stops training if the loss metric does not improve beyond the value of
    `early_stopping_threshold` after this many times of evaluation.
    """

    early_stopping_threshold: typing.Optional[float] = pydantic.Field(default=None)
    """
    How much the loss must improve to prevent early stopping.
    """

    train_batch_size: typing.Optional[int] = pydantic.Field(default=None)
    """
    The batch size is the number of training examples included in a single
    training pass.
    """

    train_epochs: typing.Optional[int] = pydantic.Field(default=None)
    """
    The number of epochs to train for.
    """

    learning_rate: typing.Optional[float] = pydantic.Field(default=None)
    """
    The learning rate to be used during training.
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef99a2c-02dc-49a3-aaea-392ab5b8d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "sys.path.append(\"..\")  # make sure we can run this from the repo\n",
    "import cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc92817c-1d42-4e85-bb88-d0f790c6a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25cbc02f-6b3f-408f-86e0-a8862b20033b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cohere.StreamingGenerations {\n",
       "\tresponse: <Response [200]>\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "streaming_gens = co.generate(prompt=\"hey! üêùüêùüêùüêù\", max_tokens=20, stream=True)\n",
    "streaming_gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d035868-42c7-429c-b57f-836eb8df7e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0][0.41s] TokenLikelihood(index=0, token='ÔøΩÔøΩ', likelihood=2e-44)\n",
      "[1][0.41s] TokenLikelihood(index=0, token='ÔøΩ', likelihood=2.1e-44)\n",
      "[2][0.41s] TokenLikelihood(index=0, token='ÔøΩ', likelihood=2.2e-44)\n",
      "[3][0.42s] TokenLikelihood(index=0, token='ÔøΩÔøΩ', likelihood=2.4e-44)\n",
      "[4][0.44s] TokenLikelihood(index=0, token='ÔøΩ', likelihood=2.5e-44)\n",
      "[5][0.47s] TokenLikelihood(index=0, token='ÔøΩ', likelihood=2.7e-44)\n",
      "[6][0.51s] TokenLikelihood(index=0, token='ÔøΩÔøΩ', likelihood=2.8e-44)\n",
      "[7][0.53s] TokenLikelihood(index=0, token='ÔøΩ', likelihood=3e-44)\n",
      "[8][0.55s] TokenLikelihood(index=0, token='ÔøΩ', likelihood=3.1e-44)\n",
      "[9][0.58s] TokenLikelihood(index=0, token='ÔøΩÔøΩ', likelihood=3.2e-44)\n",
      "[10][0.61s] TokenLikelihood(index=0, token='ÔøΩ', likelihood=3.4e-44)\n",
      "[11][0.65s] TokenLikelihood(index=0, token='ÔøΩ', likelihood=3.5e-44)\n",
      "[12][0.66s] TokenLikelihood(index=0, token='ÔøΩÔøΩ', likelihood=3.6e-44)\n",
      "[13][0.77s] TokenLikelihood(index=0, token='ÔøΩ', likelihood=3.8e-44)\n",
      "[14][0.77s] TokenLikelihood(index=0, token='ÔøΩ', likelihood=3.9e-44)\n",
      "[15][0.77s] TokenLikelihood(index=0, token='ÔøΩÔøΩ', likelihood=4e-44)\n",
      "[16][0.77s] TokenLikelihood(index=0, token='ÔøΩ', likelihood=4.2e-44)\n",
      "[17][0.80s] TokenLikelihood(index=0, token='ÔøΩ', likelihood=4.3e-44)\n",
      "[18][0.82s] TokenLikelihood(index=0, token='ÔøΩÔøΩ', likelihood=4.5e-44)\n",
      "[19][0.87s] TokenLikelihood(index=0, token='ÔøΩ', likelihood=-0.0014028251)\n"
     ]
    }
   ],
   "source": [
    "for i, token in enumerate(streaming_gens):\n",
    "    print(f\"[{i}][{time.time()-start_time:.2f}s] {token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "144ba6f3-1495-4fb3-b9f7-af9d9399ae70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cohere.StreamingGenerations {\n",
       "\tresponse: <ClientResponse(https://api.cohere.ai/generate) [200 OK]>\n",
       "<CIMultiDictProxy('Content-Type': 'application/stream+json', 'Vary': 'Origin', 'x-ratelimit-limit': '10000000', 'x-ratelimit-remaining': '9997557', 'x-ratelimit-reset': '1674403260', 'Date': 'Wed, 22 Feb 2023 15:55:31 GMT', 'Transfer-Encoding': 'chunked', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000')>\n",
       "\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aio_co = cohere.AsyncClient()\n",
    "\n",
    "start_time = time.time()\n",
    "aio_streaming_gens = await aio_co.generate(prompt=\"Cohere is the best because\", max_tokens=20, stream=True)\n",
    "aio_streaming_gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "808cb881-dc76-4668-8772-5d41abbb9b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19][0.57s] TokenLikelihood(index=0, token=' of', likelihood=1e-44)\n",
      "[19][0.57s] TokenLikelihood(index=0, token=' its', likelihood=1.1e-44)\n",
      "[19][0.57s] TokenLikelihood(index=0, token=' software', likelihood=1.3e-44)\n",
      "[19][0.57s] TokenLikelihood(index=0, token='.', likelihood=1.4e-44)\n",
      "[19][0.57s] TokenLikelihood(index=0, token=' It', likelihood=1.5e-44)\n",
      "[19][0.57s] TokenLikelihood(index=0, token=\"'s\", likelihood=1.7e-44)\n",
      "[19][0.57s] TokenLikelihood(index=0, token=' easy', likelihood=1.8e-44)\n",
      "[19][0.58s] TokenLikelihood(index=0, token=' to', likelihood=2e-44)\n",
      "[19][0.61s] TokenLikelihood(index=0, token=' use', likelihood=2.1e-44)\n",
      "[19][0.65s] TokenLikelihood(index=0, token=' and', likelihood=2.2e-44)\n",
      "[19][0.67s] TokenLikelihood(index=0, token=' works', likelihood=2.4e-44)\n",
      "[19][0.69s] TokenLikelihood(index=0, token=' well', likelihood=2.5e-44)\n",
      "[19][0.72s] TokenLikelihood(index=0, token='.', likelihood=2.7e-44)\n",
      "[19][0.78s] TokenLikelihood(index=0, token=' I', likelihood=2.8e-44)\n",
      "[19][0.78s] TokenLikelihood(index=0, token=' have', likelihood=3e-44)\n",
      "[19][0.80s] TokenLikelihood(index=0, token=' used', likelihood=3.1e-44)\n",
      "[19][0.82s] TokenLikelihood(index=0, token=' other', likelihood=3.2e-44)\n",
      "[19][0.92s] TokenLikelihood(index=0, token=' platforms', likelihood=3.4e-44)\n",
      "[19][0.92s] TokenLikelihood(index=0, token=' that', likelihood=3.5e-44)\n",
      "[19][0.92s] TokenLikelihood(index=0, token=' are', likelihood=-0.9347474)\n"
     ]
    }
   ],
   "source": [
    "async for token in aio_streaming_gens:\n",
    "    print(f\"[{i}][{time.time()-start_time:.2f}s] {token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c07bb1-2184-4bcd-942e-48a9a5690666",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For AsyncClient, use `async for` to iterate through the `StreamingGenerations`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m aio_streaming_gens:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/cohere-python/examples/../cohere/responses/generation.py:129\u001b[0m, in \u001b[0;36mStreamingGenerations.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator[StreamingTokenLikelihood, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse, requests\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m--> 129\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor AsyncClient, use `async for` to iterate through the `StreamingGenerations`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39miter_lines():\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m StreamingTokenLikelihood(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjson\u001b[38;5;241m.\u001b[39mloads(line))\n",
      "\u001b[0;31mValueError\u001b[0m: For AsyncClient, use `async for` to iterate through the `StreamingGenerations`"
     ]
    }
   ],
   "source": [
    "for token in aio_streaming_gens:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520031f6-fe67-4984-a11a-74e8e52defbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
